{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/micael/anaconda3/envs/CodeLab/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 227, in <module>\n",
      "    use(config.device)\n",
      "  File \"/home/micael/anaconda3/envs/CodeLab/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 214, in use\n",
      "    init_dev(device, preallocate=preallocate)\n",
      "  File \"/home/micael/anaconda3/envs/CodeLab/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 99, in init_dev\n",
      "    **args)\n",
      "  File \"pygpu/gpuarray.pyx\", line 658, in pygpu.gpuarray.init\n",
      "  File \"pygpu/gpuarray.pyx\", line 587, in pygpu.gpuarray.pygpu_init\n",
      "pygpu.gpuarray.GpuArrayException: b'Could not load \"libcuda.so\": libnvidia-fatbinaryloader.so.384.130: cannot open shared object file: No such file or directory'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def gen_rand(n_size=1):\n",
    "    '''\n",
    "    This function return a n_size-dimensional random vector.\n",
    "    '''\n",
    "    return np.random.random(n_size)\n",
    "\n",
    "class NN_DE(object):\n",
    "    \n",
    "    def __init__(self, n_pop=10, n_neurons=5, F=0.4, Cr=0.9, p=1, change_scheme=True ,scheme='rand',\n",
    "                 bounds=[-1, 1], max_sp_evals=np.int(1e5), sp_tol=1e-2):\n",
    "        #self.n_gens=n_gens\n",
    "        self.n_pop=n_pop\n",
    "        self.n_neurons=n_neurons\n",
    "        self.F=F*np.ones(self.n_pop)\n",
    "        self.Cr=Cr*np.ones(self.n_pop)\n",
    "        self.bounds=bounds\n",
    "        self.p=p\n",
    "        self.scheme=scheme\n",
    "        self.change_schame=change_scheme\n",
    "        self.max_sp_evals=max_sp_evals\n",
    "        self.sp_tol = sp_tol\n",
    "        self.sp_evals=0\n",
    "        self.interactions=0\n",
    "        # Build generic model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.n_neurons, input_dim=100, activation='tanh'))\n",
    "        model.add(Dense(1, activation='tanh'))\n",
    "        model.compile( loss='mean_squared_error', optimizer = 'rmsprop', metrics = ['accuracy'] )\n",
    "        self.model=model\n",
    "        self.change_schame=False\n",
    "        self.n_dim=model.count_params()\n",
    "        #self.population=NN_DE.init_population(self, pop_size=self.n_pop,\n",
    "        #                                             dim=self.n_dim, bounds=self.bounds)\n",
    "        #self.train_dataset= train_dataset\n",
    "        #self.test_dataset= test_dataset\n",
    "        \n",
    "    def init_population(self, pop_size, dim, bounds=[-1,1]):\n",
    "        '''\n",
    "        This function initialize the population to be use in DE\n",
    "        Arguments:\n",
    "        pop_size - Number of individuals (there is no default value to this yet.).\n",
    "        dim - dimension of the search space (default is 1).\n",
    "        bounds - The inferior and superior limits respectively (default is [-1, 1]).\n",
    "        '''\n",
    "        return np.random.uniform(low=bounds[0], high=bounds[1], size=(pop_size, dim))\n",
    "\n",
    "    def keep_bounds(self, pop, bounds, idx):\n",
    "        '''\n",
    "        This function keep the population in the seach space\n",
    "        Arguments:\n",
    "        pop - Population;\n",
    "        bounds - The inferior and superior limits respectively\n",
    "        '''\n",
    "        #up_ = np.where(pop>bounds[1])\n",
    "        #down_ = np.where(pop<bounds[1])\n",
    "        #best_ = pop[idx]\n",
    "        #print(pop[pop<bounds[0]])\n",
    "        #print(down_)\n",
    "        #print(best_.shape)\n",
    "        pop[pop<bounds[0]] = bounds[0]; pop[pop>bounds[1]] = bounds[1]\n",
    "        #pop[pop<bounds[0]] = 0.5*(bounds[0]+best_[down_]); pop[pop>bounds[1]] = 0.5*(bounds[1]+best_[up_])\n",
    "        return pop\n",
    "\n",
    "    # Define the Fitness to be used in DE\n",
    "    def sp_fitness(self, target, score):\n",
    "        '''\n",
    "        Calculate the SP index and return the index of the best SP found\n",
    "\n",
    "        Arguments:\n",
    "        target: True labels\n",
    "        score: the predicted labels\n",
    "        '''\n",
    "        from sklearn.metrics import roc_curve\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(target, score)\n",
    "        jpr = 1. - fpr\n",
    "        sp = np.sqrt( (tpr  + jpr)*.5 * np.sqrt(jpr*tpr) )\n",
    "        idx = np.argmax(sp)\n",
    "        return sp[idx], tpr[idx], fpr[idx]#sp, idx, sp[idx], tpr[idx], fpr[idx]\n",
    "\n",
    "    def convert_vector_weights(self, pop, nn_model):\n",
    "        \n",
    "        model = nn_model\n",
    "        \n",
    "        generic_weights = model.get_weights()\n",
    "        hl_lim = generic_weights[0].shape[0]*generic_weights[0].shape[1]\n",
    "        \n",
    "        w = []\n",
    "        hl = pop[:hl_lim]\n",
    "        ol = pop[hl_lim+generic_weights[1].shape[0]:hl_lim+generic_weights[1].shape[0]+generic_weights[1].shape[0]] \n",
    "        w.append(hl.reshape(generic_weights[0].shape))\n",
    "        w.append(pop[hl_lim:hl_lim+generic_weights[1].shape[0]])\n",
    "        w.append(ol.reshape(generic_weights[2].shape))\n",
    "        w.append(np.array(pop[-1]).reshape(generic_weights[-1].shape))\n",
    "        \n",
    "        return w\n",
    "        \n",
    "    def set_weights_to_keras_model_and_compute_fitness(self,pop, data, nn_model):\n",
    "        '''\n",
    "        This function will create a generic model and set the weights to this model and compute the fitness.\n",
    "        Arguments:\n",
    "        pop - The population of weights.\n",
    "        data - The samples to be used to test.\n",
    "        '''\n",
    "        fitness = np.zeros((pop.shape[0],3))\n",
    "        #test_fitness = np.zeros((pop.shape[0],3))\n",
    "        model=nn_model\n",
    "        \n",
    "        if pop.shape[0]!= self.n_pop:\n",
    "            #print('Local seach ind...')\n",
    "            w = NN_DE.convert_vector_weights(self, pop=pop, nn_model=model)\n",
    "            model.set_weights(w)\n",
    "            y_score = model.predict(data[0])\n",
    "            fitness = NN_DE.sp_fitness(self, target=data[1], score=y_score)\n",
    "            \n",
    "            # Compute the SP for test in the same calling to minimeze the evals\n",
    "            #test_y_score = model.predict(test_data[0])\n",
    "            #test_fitness = NN_DE.sp_fitness(self, target=test_data[1], score=test_y_score)\n",
    "            return fitness#, test_fitness\n",
    "        \n",
    "        for ind in range(pop.shape[0]):\n",
    "            w = NN_DE.convert_vector_weights(self, pop=pop[ind], nn_model=model)\n",
    "            model.set_weights(w)\n",
    "            y_score = model.predict(data[0])\n",
    "            fitness[ind] = NN_DE.sp_fitness(self, target=data[1], score=y_score)\n",
    "            \n",
    "            # Compute the SP for test in the same calling to minimeze the evals\n",
    "            #test_y_score = model.predict(test_data[0])\n",
    "            #test_fitness[ind] = NN_DE.sp_fitness(self, target=test_data[1], score=test_y_score)\n",
    "            #print('Population ind: {} - SP: {} - PD: {} - PF: {}'.format(ind, fitness[ind][0], fitness[ind][1], fitness[ind][2]))\n",
    "        return fitness#, test_fitness\n",
    "\n",
    "\n",
    "    def evolution(self, dataset):\n",
    "        \n",
    "        self.population=NN_DE.init_population(self, pop_size=self.n_pop,\n",
    "                                              dim=self.n_dim, bounds=self.bounds)\n",
    "        r_NNDE = {}\n",
    "        fitness = NN_DE.set_weights_to_keras_model_and_compute_fitness(self, pop=self.population,\n",
    "                                                                       data=dataset,\n",
    "                                                                       nn_model=self.model)\n",
    "        best_idx = np.argmax(fitness[:,0])\n",
    "        \n",
    "        # Create the vectors F and Cr to be adapted during the interactions\n",
    "        NF = np.zeros_like(self.F)\n",
    "        NCr = np.zeros_like(self.Cr)\n",
    "        # Create a log\n",
    "        r_NNDE['log'] = []\n",
    "        r_NNDE['log'].append((self.sp_evals, fitness[best_idx], np.mean(fitness, axis=0),\n",
    "                             np.std(fitness, axis=0), np.min(fitness, axis=0), np.median(fitness, axis=0), self.F, self.Cr))\n",
    "\n",
    "        #r_NNDE['test_log'] = []\n",
    "        #r_NNDE['test_log'].append((self.sp_evals, test_fitness[best_idx], np.mean(test_fitness, axis=0),\n",
    "                             #np.std(test_fitness, axis=0), np.min(test_fitness, axis=0), np.median(test_fitness, axis=0), self.F, self.Cr))\n",
    "\n",
    "        while self.sp_evals < self.max_sp_evals:\n",
    "            # ============ Mutation Step ===============\n",
    "            mutant = np.zeros_like(self.population)\n",
    "            for ind in range(self.population.shape[0]):\n",
    "                if gen_rand() < 0.1:\n",
    "                    NF[ind] = 0.2 +0.2*gen_rand()\n",
    "                else:\n",
    "                    NF[ind] = self.F[ind]\n",
    "                tmp_pop = np.delete(self.population, ind, axis=0)\n",
    "                choices = np.random.choice(tmp_pop.shape[0], 1+2*self.p, replace=False)\n",
    "                diffs = 0\n",
    "                for idiff in range(1, len(choices), 2):\n",
    "                    diffs += NF[ind]*((tmp_pop[choices[idiff]]-tmp_pop[choices[idiff+1]]))\n",
    "                    if self.scheme=='rand':\n",
    "                        mutant[ind] = tmp_pop[choices[0]] + diffs\n",
    "                    elif self.scheme=='best':\n",
    "                        mutant[ind] = self.population[best_idx] + diffs\n",
    "            # keep the bounds\n",
    "            mutant = NN_DE.keep_bounds(self, mutant, bounds=[-1,1], idx=best_idx)\n",
    "\n",
    "            # ============ Crossover Step ============= \n",
    "            trial_pop = np.copy(self.population)\n",
    "            K = np.random.choice(trial_pop.shape[1])\n",
    "            for ind in range(trial_pop.shape[0]):\n",
    "                if gen_rand() < 0.1:\n",
    "                    NCr[ind] = 0.8 +0.2*gen_rand()\n",
    "                else:\n",
    "                    NCr[ind] = self.Cr[ind]\n",
    "                for jnd in range(trial_pop.shape[1]):\n",
    "                    if jnd == K or gen_rand()<NCr[ind]:\n",
    "                        trial_pop[ind][jnd] = mutant[ind][jnd]\n",
    "            # keep the bounds\n",
    "            trial_pop = NN_DE.keep_bounds(self, trial_pop, bounds=[-1,1], idx=best_idx)\n",
    "\n",
    "            trial_fitness = NN_DE.set_weights_to_keras_model_and_compute_fitness(self, pop=trial_pop,\n",
    "                                                                                 data=dataset,\n",
    "                                                                                 nn_model=self.model)\n",
    "            self.sp_evals += self.population.shape[0]\n",
    "            \n",
    "            # ============ Selection Step ==============\n",
    "            winners = np.where(trial_fitness[:,0]>fitness[:,0])\n",
    "        \n",
    "            # Auto-adtaptation of F and Cr like NSSDE\n",
    "            self.F[winners] = NF[winners]\n",
    "            self.Cr[winners] = NCr[winners]\n",
    "            \n",
    "            # Greedy Selection\n",
    "            fitness[winners] = trial_fitness[winners]\n",
    "            self.population[winners] = trial_pop[winners]\n",
    "            best_idx = np.argmax(fitness[:,0])\n",
    "            \n",
    "            if self.interactions > 0.95*self.max_sp_evals/self.n_pop:\n",
    "                print('=====Interaction: {}====='.format(self.interactions+1))\n",
    "                print('Best NN found - SP: {} / PD: {} / FA: {}'.format(fitness[best_idx][0],\n",
    "                                                                        fitness[best_idx][1],\n",
    "                                                                        fitness[best_idx][2]))\n",
    "            \n",
    "                #print('Test > Mean - SP: {} +- {}'.format(np.mean(test_fitness,axis=0)[0],\n",
    "                #                                                    np.std(test_fitness,axis=0)[0]))\n",
    "                \n",
    "            # Local search like NSSDE \n",
    "            a_1 = gen_rand(); a_2 = gen_rand()\n",
    "            a_3 = 1.0 - a_1 - a_2\n",
    "            \n",
    "            k, r1, r2 = np.random.choice(self.population.shape[0], size=3)\n",
    "            V = np.zeros_like(self.population[k])\n",
    "            for jdim in range(self.population.shape[1]):\n",
    "                V[jdim] = a_1*self.population[k][jdim] + a_2*self.population[best_idx][jdim] + a_3*(self.population[r1][jdim] - self.population[r2][jdim])\n",
    "                V = NN_DE.keep_bounds(self, V, bounds=self.bounds, idx=best_idx)\n",
    "            \n",
    "            \n",
    "            V_train_fitness = NN_DE.set_weights_to_keras_model_and_compute_fitness(self, pop=V,\n",
    "                                                                                   data=dataset,\n",
    "                                                                                   nn_model=self.model)\n",
    "            \n",
    "            self.sp_evals += 1\n",
    "            if V_train_fitness[0] > fitness[k][0]:\n",
    "                #print('Found best model using local search...')\n",
    "                self.population[k] = V\n",
    "                if V_train_fitness[0] > fitness[best_idx][0]:\n",
    "                    best_idx = k\n",
    "            \n",
    "            # ======== Done interaction ===========\n",
    "            self.interactions += 1\n",
    "            \n",
    "            r_NNDE['log'].append((self.sp_evals, fitness[best_idx], np.mean(fitness, axis=0),\n",
    "                             np.std(fitness, axis=0), np.min(fitness, axis=0), np.median(fitness, axis=0), self.F, self.Cr))\n",
    "            \n",
    "            #r_NNDE['test_log'].append((self.sp_evals, test_fitness[best_idx], np.mean(test_fitness, axis=0),\n",
    "            #                 np.std(test_fitness, axis=0), np.min(test_fitness, axis=0), np.median(test_fitness, axis=0), self.F, self.Cr))\n",
    "            \n",
    "            #print('Fitness: ', fitness[:,0])\n",
    "            #print('Mean: ',np.mean(fitness[:,0]))\n",
    "            if np.mean(fitness[:,0]) > .9 and np.abs(np.mean(fitness[:,0])-fitness[best_idx][0])< self.sp_tol:\n",
    "                print('Stop by Mean Criteria...')\n",
    "                break\n",
    "        # Compute the test\n",
    "        #test_fitness = NN_DE.set_weights_to_keras_model_and_compute_fitness(self, pop=self.population,\n",
    "        #                                                               data=self.test_dataset, nn_model=self.model)\n",
    "\n",
    "        r_NNDE['champion weights'] = NN_DE.convert_vector_weights(self, self.population[best_idx], self.model)\n",
    "        r_NNDE['model'] = self.model\n",
    "        r_NNDE['best index'] = best_idx\n",
    "        r_NNDE['Best NN'] = fitness[best_idx]\n",
    "        r_NNDE['fitness'] = fitness\n",
    "        #r_NNDE['test_fitness'] = test_fitness\n",
    "        r_NNDE['population'] = self.population,\n",
    "        return r_NNDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/micael/MyWorkspace/RingerRepresentation/2channels/data17-18_13TeV.sgn_lhmedium_probes.EGAM2.bkg.vetolhvloose.EGAM7.samples.npz')\n",
    "sgn = data['signalPatterns_etBin_2_etaBin_0']\n",
    "bkg = data['backgroundPatterns_etBin_2_etaBin_0']\n",
    "\n",
    "# Equilibrate the classes to make a controled tests\n",
    "bkg = bkg[np.random.choice(bkg.shape[0], size=sgn.shape[0]),:]\n",
    "#print(sgn.shape, bkg.shape)\n",
    "\n",
    "sgn_trgt = np.ones(sgn.shape[0])\n",
    "bkg_trgt = -1*np.ones(bkg.shape[0])\n",
    "\n",
    "sgn_normalized = np.zeros_like(sgn)\n",
    "for ind in range(sgn.shape[0]):\n",
    "    sgn_normalized[ind] = sgn[ind]/np.abs(np.sum(sgn[ind]))\n",
    "    \n",
    "bkg_normalized = np.zeros_like(bkg)\n",
    "for ind in range(bkg.shape[0]):\n",
    "    bkg_normalized[ind] = bkg[ind]/np.abs(np.sum(bkg[ind]))\n",
    "\n",
    "data_ = np.append(sgn_normalized, bkg_normalized, axis=0)\n",
    "trgt = np.append(sgn_trgt, bkg_trgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_dict = {}\n",
    "nn_de = NN_DE(n_pop=20, max_sp_evals=2e3, scheme='best', sp_tol=1e-3)\n",
    "for irun in range(n_runs):\n",
    "    init_run_time = time.time()\n",
    "    print('Begin Run {}'.format(irun+1))\n",
    "    result_dict['Run {}'.format(irun+1)] = nn_de.evolution(dataset=(data_, trgt))\n",
    "    end_run_time = time.time()\n",
    "    print('Run {} - Time: {}'.format(irun+1, end_run_time - init_run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Run 8',\n",
       " 'Run 10',\n",
       " 'Run 4',\n",
       " 'Run 9',\n",
       " 'Run 2',\n",
       " 'Run 1',\n",
       " 'Run 6',\n",
       " 'Run 7',\n",
       " 'Run 5',\n",
       " 'Run 3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8 > [ 0.90788686  0.92687464  0.11090441]\n",
      "Run 10 > [ 0.90601017  0.93216943  0.11977676]\n",
      "Run 4 > [ 0.9056507   0.9184316   0.10704064]\n",
      "Run 9 > [ 0.91943109  0.92229536  0.08342873]\n",
      "Run 2 > [ 0.91953231  0.93231254  0.0931597 ]\n",
      "Run 1 > [ 0.91060131  0.92129365  0.10002862]\n",
      "Run 6 > [ 0.92377269  0.93345736  0.08586148]\n",
      "Run 7 > [ 0.9299779   0.95091586  0.09072696]\n",
      "Run 5 > [ 0.93047869  0.94347453  0.08242702]\n",
      "Run 3 > [ 0.93550415  0.95492272  0.08371494]\n",
      "[ 91.8884586  93.3614768   9.5706926] [ 1.0434345  1.1875513  1.2476335]\n",
      "Pop:  [ 91.867213   93.4919147   9.7405552] [ 1.0184136  1.0893271  1.0670021]\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "m = []\n",
    "for ifold in return_dict.keys():\n",
    "    print(ifold, '>', return_dict[ifold]['fitness'][return_dict[ifold]['best index']])\n",
    "    r.append(return_dict[ifold]['fitness'][return_dict[ifold]['best index']])\n",
    "    m.append(np.mean(return_dict[ifold]['fitness'], axis=0))\n",
    "    #print('population: {}+-{}'.format(np.around(np.mean(return_dict[ifold]['fitness'], axis=0),7),\n",
    "    #      np.around(np.std(return_dict[ifold]['fitness'], axis=0),7)))\n",
    "print(np.around(100*np.mean(r, axis=0),7), np.around(100*np.std(r, axis=0),7))\n",
    "print('Pop: ', np.around(100*np.mean(m, axis=0),7), np.around(100*np.std(m, axis=0),7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ = {}\n",
    "for ifold in return_dict.keys():\n",
    "    print(len(return_dict[ifold]['log']))\n",
    "    checks = list(range(0,len(return_dict[ifold]['log'])))\n",
    "    r_[ifold]={}\n",
    "    r_[ifold]['train'] = []\n",
    "    #r_[ifold]['test'] = []\n",
    "    for icheck in checks:\n",
    "        #print(ifold, '>', return_dict[ifold]['log'][icheck][2])\n",
    "        r_[ifold]['train'].append(return_dict[ifold]['log'][icheck][2])\n",
    "        #r_[ifold]['test'].append(return_dict[ifold]['test_log'][icheck][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merits = {\n",
    "    'SP'  : 'SP Index',\n",
    "    'PD'  : 'PD',\n",
    "    'FA'  : 'FA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('_classic_test')\n",
    "\n",
    "folds = ['Run 1', 'Run 2', 'Run 3', 'Run 4', 'Run 5', 'Run 6', 'Run 7', 'Run 8', 'Run 9', 'Run 10']\n",
    "#x_axis = np.array([0., 20, 100, 1000,2000,3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "\n",
    "for idx, imerit in enumerate(merits.keys()):\n",
    "    print('Plot: ', imerit)\n",
    "    #f, (ax1, ax2) = plt.subplots(1, 2, sharey=False, figsize=(15,5))\n",
    "    for ifold in folds:\n",
    "\n",
    "        plt.plot(np.array(r_[ifold]['train'])[:,idx], label=ifold)\n",
    "        plt.legend(fontsize='large', loc='best')\n",
    "        plt.title(merits[imerit]+' - Train', fontsize=15)\n",
    "        plt.xlabel('Interactions', fontsize=10)\n",
    "        plt.ylabel('Mean '+merits[imerit], fontsize=10)\n",
    "        plt.grid(True)\n",
    "\n",
    "        #ax2.plot(np.array(r_[ifold]['test'])[:,idx], label=ifold)\n",
    "        #ax2.legend(fontsize='large', loc='best')\n",
    "        #ax2.set_title(merits[imerit]+' - Test', fontsize=15)\n",
    "        #ax2.set_xlabel('Interactions', fontsize=10)\n",
    "        #ax2.set_ylabel('Mean '+merits[imerit], fontsize=10)\n",
    "        #ax2.grid(True)\n",
    "    #plt.savefig(merits[imerit]+'.rand1bin.2000evals.withLS.MeanStopCriteria.pdf',)\n",
    "    #plt.savefig(merits[imerit]+'.rand1bin.2000evals.withLS.MeanStopCriteria.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(return_dict))\n",
    "return_dict = dict(return_dict)\n",
    "print(type(return_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict['CVO'] = CVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict['CVO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('nnde.5neurons.rand1bin.2000evals.withLS.MeanStopCriteria.pickle', 'wb') as handle:\n",
    "    pickle.dump(return_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here begin the Backpropagation\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Get the champions and set the model.\n",
    "2. Fit the model in each fold.\n",
    "3. Get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(number_of_epoch):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict['Fold 1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dict['Fold 1']['champion weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "inicio = time.time()\n",
    "nn_de = NN_DE(n_pop=20, max_sp_evals=1e4, scheme='rand')\n",
    "resultado = {}\n",
    "for ifold, (train_index, test_index) in enumerate(CVO):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index, \"Fold: \", ifold)\n",
    "    resultado['Fold {}'.format(ifold+1)] = nn_de.evolution(train_dataset=(data_[train_index], trgt[train_index]),\n",
    "                                                           test_dataset=(data_[test_index], trgt[test_index]))\n",
    "fim=time.time()\n",
    "\n",
    "print('Demorou - {} segundos'.format(fim-inicio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado['Fold 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = {}\n",
    "for train_index, test_index in skf.split(data_, trgt):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = NN_DE(n_pop=20,max_sp_evals=2e3, scheme='rand', sp_tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = teste.evolution(train_dataset=(data_, trgt), test_dataset=(data_, trgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev['log'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(ev['fitness'],axis=0), np.std(ev['fitness'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(ev['fitness'][:,0]), ev['best index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev['fitness'][ev['best index']], ev['fitness'][np.argmin(ev['fitness'][:,0])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
